{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60182a2f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.sql.types import StructField, StructType, DoubleType\n",
    "from pyspark.ml.feature import (StringIndexer, VectorIndexer, OneHotEncoderEstimator, VectorAssembler, IndexToString,)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "from mleap.pyspark.spark_support import SimpleSparkSerializer\n",
    "from __future__ import print_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6593cc84",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"fixed acidity\", DoubleType(), True),\n",
    "        StructField(\"volatile acidity\", DoubleType(), True),\n",
    "        StructField(\"citric acid\", DoubleType(), True),\n",
    "        StructField(\"residual sugar\", DoubleType(), True),\n",
    "        StructField(\"chlorides\", DoubleType(), True),\n",
    "        StructField(\"free sulfur dioxide\", DoubleType(), True),\n",
    "        StructField(\"total sulfur dioxide\", DoubleType(), True),\n",
    "        StructField(\"density\", DoubleType(), True),\n",
    "        StructField(\"pH\", DoubleType(), True),\n",
    "        StructField(\"sulphates\", DoubleType(), True),\n",
    "        StructField(\"alcohol\", DoubleType(), True),\n",
    "        StructField(\"quality\", DoubleType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed9804ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainD = spark.read.csv(\n",
    "    \"s3://643wine/TrainingDataset.csv\", header=False, schema=schema\n",
    ")\n",
    "\n",
    "validD = spark.read.csv(\n",
    "    \"s3://643wine/ValidationDataset.csv\", header=False, schema=schema\n",
    ")\n",
    "\n",
    "trainD.show(5)\n",
    "(train_df, validation_df) = (traindD, validD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258bd91d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95633d04",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The code failed because of a fatal error:\n",
      "\tError sending http request and maximum retry encountered..\n",
      "\n",
      "Some things to try:\n",
      "a) Make sure Spark has enough available resources for Jupyter to create a Spark context.\n",
      "b) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\n",
      "c) Restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(maxDepth=6, numTrees=18)\n",
    "\n",
    "model = rf.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a723627",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_train = model.transform(train_df)\n",
    "transform_valid = model.transform(validation_df)\n",
    "\n",
    "train_rmse = evaluator.evaluate(transformed_train)\n",
    "validation_rmse = evaluator.evaluate(transformed_valid)\n",
    "\n",
    "print(\"Train RMSE = %g\" % train_rmse)\n",
    "print(\"Validation RMSE = %g\" % validation_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
